# dags/etl_dag.py
from __future__ import annotations
import datetime
import pendulum
import sys
from airflow.models.dag import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.utils.context import Context
from airflow.utils.email import send_email
from psycopg2.sql import SQL, Identifier
from pathlib import Path
import logging, traceback
from airflow.exceptions import AirflowException
from psycopg2 import OperationalError, ProgrammingError, DataError, InterfaceError

logger = logging.getLogger(__name__)

# Adiciona o diret√≥rio `etl` ao PYTHONPATH para que os scripts possam ser importados
sys.path.append(str(Path(__file__).parent.parent / "etl"))

# Importa as fun√ß√µes principais dos seus scripts
from extract import main as extract_main
from transform import main as transform_main
from load import main as load_main

# Callback para falhas - ENVIA EMAIL REAL
def send_alert_on_failure(context: Context):
    """
    Fun√ß√£o para enviar alerta em caso de falha na tarefa
    """
    try:
        dag_id = context['dag'].dag_id
        task_id = context['task_instance'].task_id
        execution_date = context.get('execution_date', 'N/A')
        
        # Formata a data se estiver dispon√≠vel
        if execution_date != 'N/A' and hasattr(execution_date, 'strftime'):
            execution_date_str = execution_date.strftime('%Y-%m-%d %H:%M:%S')
        else:
            execution_date_str = str(execution_date)
        
        # Captura a exce√ß√£o real e traceback completo
        exception = context.get('exception')
        if exception:
            error_message = str(exception)
            traceback_msg = ''.join(traceback.format_exception(
                type(exception), exception, exception.__traceback__
            ))
        else:
            error_message = "Erro desconhecido (sem exce√ß√£o capturada)"
            traceback_msg = "Nenhum traceback dispon√≠vel"
        
        # Log do erro
        logger.error(f"‚ùå Falha na tarefa {task_id} do DAG {dag_id}")
        logger.error(f"üìÖ Data de execu√ß√£o: {execution_date_str}")
        logger.error(f"üí° Mensagem de erro: {error_message}")
        
        # Email com detalhes t√©cnicos completos
        subject = f"üö® ALERTA: Falha no Airflow - DAG: {dag_id}, Tarefa: {task_id}"
        body = f"""
        <h3>üö® Falha detectada no processo ETL</h3>
        
        <strong>üìã Detalhes da Tarefa:</strong><br>
        ‚Ä¢ <strong>DAG:</strong> {dag_id}<br>
        ‚Ä¢ <strong>Tarefa:</strong> {task_id}<br>
        ‚Ä¢ <strong>Data de execu√ß√£o:</strong> {execution_date_str}<br><br>
        
        <strong>‚ùå Mensagem de Erro:</strong><br>
        <pre>{error_message}</pre><br>
        
        <strong>üîç Detalhe T√©cnico Completo:</strong><br>
        <pre>{traceback_msg}</pre><br>
        
        <strong>üìä Status:</strong> FALHA<br>
        <strong>üïí Hora da falha:</strong> {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}<br><br>
        
        <em>Por favor, verifique os logs do Airflow para mais detalhes.</em>
        """
        
        logger.info(f"üìß Tentando enviar email de alerta: {subject}")
        
        # ENVIA EMAIL REAL
        try:
            send_email(
                to=['bugdroidgamesbr@gmail.com', 'nando.devs@gmail.com'],
                subject=subject,
                html_content=body
            )
            logger.info("‚úÖ Email de alerta enviado com sucesso!")
        except Exception as email_error:
            logger.error(f"‚ùå Falha ao enviar email: {email_error}")
            logger.error(traceback.format_exc())
        
    except Exception as e:
        logger.error(f"‚ùå Erro no sistema de alertas: {str(e)}")
        logger.error(traceback.format_exc())

# Callback para sucesso do DAG completo
def dag_success_callback(context: Context):
    """Callback para quando o DAG inteiro √© executado com sucesso"""
    try:
        dag_id = context['dag'].dag_id
        execution_date = context.get('execution_date', 'N/A')
        
        if execution_date != 'N/A' and hasattr(execution_date, 'strftime'):
            execution_date_str = execution_date.strftime('%Y-%m-%d %H:%M:%S')
        else:
            execution_date_str = str(execution_date)
        
        subject = f"‚úÖ SUCESSO: DAG {dag_id} executado com sucesso"
        body = f"""
        <h3>‚úÖ Processamento ETL Conclu√≠do com Sucesso</h3>
        
        <strong>üìã Detalhes:</strong><br>
        ‚Ä¢ <strong>DAG:</strong> {dag_id}<br>
        ‚Ä¢ <strong>Data de execu√ß√£o:</strong> {execution_date_str}<br>
        ‚Ä¢ <strong>Status:</strong> SUCESSO COMPLETO<br>
        ‚Ä¢ <strong>Hora de conclus√£o:</strong> {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}<br><br>
        
        <strong>üìä Fluxo executado:</strong><br>
        ‚úÖ Extra√ß√£o de dados da API<br>
        ‚úÖ Transforma√ß√£o e limpeza dos dados<br>
        ‚úÖ Cria√ß√£o do banco de dados<br>
        ‚úÖ Carga no Data Warehouse<br>
        ‚úÖ Valida√ß√£o da qualidade<br>
        ‚úÖ Relat√≥rio final<br><br>
        
        <em>Todas as tarefas foram executadas com sucesso!</em>
        """
        
        logger.info(f"üìß Tentando enviar email de sucesso: {subject}")
        
        try:
            send_email(
                to=['bugdroidgamesbr@gmail.com', 'nando.devs@gmail.com'],
                subject=subject,
                html_content=body
            )
            logger.info("‚úÖ Email de sucesso enviado!")
        except Exception as email_error:
            logger.error(f"‚ùå Falha ao enviar email de sucesso: {email_error}")
                
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Erro no callback de sucesso do DAG: {e}")

# Configura√ß√£o dos callbacks
on_failure_callback = send_alert_on_failure

with DAG(
    dag_id="case_tecnico_maxinutri",
    start_date=pendulum.datetime(2023, 1, 1, tz="UTC"),
    schedule="@daily",
    catchup=False,
    tags=["etl", "desafio"],
    on_success_callback=dag_success_callback,  # Callback para sucesso do DAG completo
    default_args={
        'owner': "Sisnando Junior",
        'start_date': pendulum.datetime(2023, 1, 1, tz="UTC"),
        'on_failure_callback': on_failure_callback,
        'email_on_failure': False,  # Desativa emails padr√£o do Airflow
        'email_on_retry': False,
        'retries': 2,
        'retry_delay': pendulum.duration(minutes=5),
        'execution_timeout': pendulum.duration(minutes=120),
    }
) as dag:
    
    def run_extract_task():
        """Executa a extra√ß√£o dos dados."""
        try:
            logger.info("Iniciando extra√ß√£o de dados da API...")
            extract_main()
            logger.info("‚úÖ Extra√ß√£o conclu√≠da com sucesso.")
        except Exception as e:
            logger.error(f"‚ùå Erro na extra√ß√£o: {e}")
            logger.error(traceback.format_exc())
            raise

    def run_transform_task():
        """Executa a transforma√ß√£o dos dados."""
        try:
            logger.info("Iniciando transforma√ß√£o de dados...")
            transform_main()
            logger.info("‚úÖ Transforma√ß√£o conclu√≠da com sucesso.")
        except Exception as e:
            logger.error(f"‚ùå Erro na transforma√ß√£o: {e}")
            logger.error(traceback.format_exc())
            raise

    def run_create_database():
        """Cria o banco de dados se ele n√£o existir."""
        hook = PostgresHook(postgres_conn_id="postgres-default")
        conn = None
        cur = None
        try:
            conn = hook.get_conn()
            conn.autocommit = True
            cur = conn.cursor()
            
            db_name = "desafio_db"

            cur.execute(SQL("SELECT 1 FROM pg_database WHERE datname = %s"), (db_name,))
            exists = cur.fetchone()

            if not exists:
                logger.info(f"Criando o banco de dados '{db_name}'...")
                cur.execute(SQL("CREATE DATABASE {}").format(Identifier(db_name)))
                logger.info(f"‚úÖ Banco de dados '{db_name}' criado com sucesso.")
            else:
                logger.info(f"üìä Banco de dados '{db_name}' j√° existe.")

        except OperationalError as e:
            logger.error(f"‚ùå Erro de conex√£o ao criar banco: {e}")
            logger.error(traceback.format_exc())
            raise
        except ProgrammingError as e:
            logger.error(f"‚ùå Erro de SQL ao criar banco: {e}")
            logger.error(traceback.format_exc())
            raise
        except Exception as e:
            logger.error(f"‚ùå Erro inesperado ao criar banco: {e}")
            logger.error(traceback.format_exc())
            raise
        finally:
            if cur:
                cur.close()
            if conn:
                conn.close()
    
    def run_load_task():
        """Cria a conex√£o e executa o carregamento dos dados no banco de dados."""
        conn = None
        cur = None
        try:
            hook = PostgresHook(postgres_conn_id="postgres-default")
            conn = hook.get_conn()
            conn.autocommit = False
            
            # Configura timeout para evitar opera√ß√µes muito longas
            cur = conn.cursor()
            cur.execute("SET statement_timeout = 300000;")  # 5 minutos
            
            logger.info("Iniciando carga de dados...")
            load_main(cur=cur)
            conn.commit()
            logger.info("‚úÖ Dados carregados com sucesso.")
            
        except (OperationalError, InterfaceError) as e:
            logger.error(f"‚ùå Erro de conex√£o durante carga: {e}")
            logger.error(traceback.format_exc())
            if conn:
                conn.rollback()
            raise
        except DataError as e:
            logger.error(f"‚ùå Erro de dados durante carga: {e}")
            logger.error(traceback.format_exc())
            if conn:
                conn.rollback()
            raise
        except Exception as e:
            logger.error(f"‚ùå Erro inesperado durante carga: {e}")
            logger.error(traceback.format_exc())
            if conn:
                conn.rollback()
            raise
        finally:
            if cur:
                cur.close()
            if conn:
                conn.close()

    def validate_etl_process():
        """Valida√ß√£o simplificada do ETL."""
        hook = PostgresHook(postgres_conn_id="postgres-default", schema="desafio_db")
        conn = None
        cur = None
        try:
            conn = hook.get_conn()
            cur = conn.cursor()
            
            # Lista de verifica√ß√µes a serem realizadas
            checks = [
                ("Tabelas existem", """
                    SELECT COUNT(*) 
                    FROM information_schema.tables 
                    WHERE table_schema = 'public'
                    AND table_name IN ('dim_cliente', 'dim_produto', 'dim_tempo', 'dim_avaliacao', 'fato_pedido')
                """),
                ("Total de clientes", "SELECT COUNT(*) FROM dim_cliente"),
                ("Total de produtos", "SELECT COUNT(*) FROM dim_produto"),
                ("Total de pedidos", "SELECT COUNT(*) FROM fato_pedido"),
                ("Pedidos v√°lidos", "SELECT COUNT(*) FROM fato_pedido WHERE preco > 0 AND frete >= 0")
            ]
            
            results = {}
            
            for check_name, query in checks:
                try:
                    cur.execute(query)
                    result = cur.fetchone()[0]
                    results[check_name] = result
                    logger.info(f"{check_name}: {result}")
                except Exception as e:
                    logger.warning(f"Falha na verifica√ß√£o '{check_name}': {e}")
                    results[check_name] = f"Erro: {e}"
            
            # Verificar se todas as tabelas essenciais existem
            if results.get("Tabelas existem", 0) < 5:
                raise Exception("N√£o todas as tabelas foram criadas corretamente")
            
            # Verificar se h√° dados nas tabelas principais
            if results.get("Total de pedidos", 0) == 0:
                logger.warning("‚ö†Ô∏è  Tabela de pedidos est√° vazia")
            
            if results.get("Total de clientes", 0) == 0:
                logger.warning("‚ö†Ô∏è  Tabela de clientes est√° vazia")
            
            if results.get("Total de produtos", 0) == 0:
                logger.warning("‚ö†Ô∏è  Tabela de produtos est√° vazia")
            
            logger.info("‚úÖ Valida√ß√£o conclu√≠da com sucesso")
            logger.info(f"üìä Resultados: {results}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Falha na valida√ß√£o: {e}")
            logger.error(traceback.format_exc())
            raise
        finally:
            if cur:
                cur.close()
            if conn:
                conn.close()

    def send_final_report():
        """Envia relat√≥rio final do processamento."""
        try:
            logger.info("üìä Preparando relat√≥rio final do ETL...")
            
            # Simula envio de relat√≥rio
            logger.info("‚úÖ Processamento ETL conclu√≠do com sucesso!")
            logger.info("üìã Relat√≥rio:")
            logger.info("  ‚úÖ Extra√ß√£o: Dados extra√≠dos da API")
            logger.info("  ‚úÖ Transforma√ß√£o: Dados limpos e processados")
            logger.info("  ‚úÖ Carga: Dados carregados no Data Warehouse")
            logger.info("  ‚úÖ Valida√ß√£o: Qualidade dos dados verificada")
            logger.info("  üìä Status: Pipeline completo executado com sucesso")
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Falha ao enviar relat√≥rio: {e}")
            logger.error(traceback.format_exc())

    # Tarefa de teste para verificar alertas
    def test_failure_task():
        """Tarefa de teste que falha propositalmente"""
        raise ConnectionError("‚ùå ERRO DE CONEX√ÉO: Falha simulada para testar alertas de email - Timeout na conex√£o com PostgreSQL")

    # Definindo as tarefas
    extract_task = PythonOperator(
        task_id="extract_data_from_api",
        python_callable=run_extract_task,
        retries=2,
        retry_delay=pendulum.duration(seconds=30),
        execution_timeout=pendulum.duration(minutes=30),
    )

    transform_task = PythonOperator(
        task_id="transform_data",
        python_callable=run_transform_task,
        retries=2,
        retry_delay=pendulum.duration(seconds=30),
        execution_timeout=pendulum.duration(minutes=30),
    )

    create_db_task = PythonOperator(
        task_id="create_database_if_not_exists",
        python_callable=run_create_database,
        retries=2,
        retry_delay=pendulum.duration(seconds=30),
        execution_timeout=pendulum.duration(minutes=5),
    )

    load_task = PythonOperator(
        task_id="load_data_to_postgres",
        python_callable=run_load_task,
        retries=3,
        retry_delay=pendulum.duration(seconds=60),
        execution_timeout=pendulum.duration(minutes=60),
    )

    validate_task = PythonOperator(
        task_id="validate_etl_process",
        python_callable=validate_etl_process,
        retries=1,
        retry_delay=pendulum.duration(seconds=30),
        execution_timeout=pendulum.duration(minutes=10),
    )

    report_task = PythonOperator(
        task_id="send_final_report",
        python_callable=send_final_report,
        retries=1,
        retry_delay=pendulum.duration(seconds=15),
        execution_timeout=pendulum.duration(minutes=5),
    )

    # test_task = PythonOperator(
    #     task_id="test_alert_system",
    #     python_callable=test_failure_task,
    #     retries=0,
    #     execution_timeout=pendulum.duration(minutes=2),
    # )

    # Definindo as depend√™ncias principais
    extract_task >> transform_task >> create_db_task >> load_task >> validate_task >> report_task

    # ‚ö†Ô∏è PARA TESTAR ALERTAS: Descomente a linha abaixo
    # test_task  # Remove o coment√°rio para testar os alertas de email